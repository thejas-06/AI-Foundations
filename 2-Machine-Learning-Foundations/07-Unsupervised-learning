# Unsupervised Machine Learning - Learning Notes

## Overview
In this lesson, we learn about **unsupervised machine learning**, a type of machine learning where there are no labeled outputs. The algorithm learns patterns and relationships in the data and groups similar data items. The video explains clustering, similarity measures, and key use cases like market segmentation, outlier detection, and recommendation systems.

## Key Concepts
- **Unsupervised Machine Learning**: Learning patterns in unlabeled data without being told what to look for.
- **Clustering**: Grouping data items based on similarities, with items inside a cluster being more similar than those outside.
- **Outliers**: Data items that do not fit into any cluster.
- **Similarity**: A measure of how close two data points are, with values between 0 and 1.

## Detailed Notes

### Introduction
- In unsupervised machine learning, there are no labeled outputs.
- The algorithm explores patterns in the data explicitly.
- Example:  
  - Giving a child a set of colored LEGO pieces, the child may group them based on patterns like color, size, or type.  
  - Similarly, unlabeled datasets are grouped into clusters.

### Examples
- **Fruit Basket Example**:  
  - A basket has apples, bananas, and oranges.  
  - Round red fruits are grouped together (apples).  
  - Elongated yellow fruits are grouped together (bananas).  
  - This grouping is an unsupervised learning task.

### Clustering
- **Definition**: A method of grouping data items based on similarities.  
- **Cluster Properties**:  
  - Items within a cluster are more similar than those outside.  
  - Items not belonging to any cluster are **outliers**.  
- Example: Grapes differ in shape, size, and color compared to apples, pears, and strawberries, and could be considered outliers.

### Use Cases
1. **Market Segmentation**  
   - Input: Purchasing details of customers.  
   - Example: Clustering customers based on purchasing behavior.  
   - Outcome: Identifies customers (e.g., young people buying protein products) for targeted ads like sports products.

2. **Outlier Analysis**  
   - Example: Credit card transactions.  
   - Fraudulent transactions (e.g., very high or recurring amounts) appear as outliers.

3. **Recommendation Systems**  
   - Input: Users’ movie viewing history.  
   - Outcome: Clusters users by type or rating of movies watched.  
   - Application: Provides personalized recommendations (e.g., Netflix, music platforms).

### Similarity
- **Definition**: How close two data points are (value between 0 and 1).  
- Determines which cluster objects belong to.  
- Example: Apple and cherry are similar based on color → similarity value close to 1.  
- **Types of Similarity Metrics**:  
  - Euclidean distance  
  - Manhattan distance  
  - Cosine similarity  
  - Jaccard similarity

### Workflow of Unsupervised Learning
1. **Prepare the Data**  
   - Preprocessing steps: removing missing values, normalizing, feature scaling.  

2. **Create Similarity Matrix**  
   - Choice depends on data nature and clustering algorithm.  
   - Common metrics: Euclidean, Manhattan, Cosine, Jaccard.  

3. **Run Clustering Algorithm**  
   - Algorithms use similarity matrix to form clusters.  
   - Types of clustering algorithms:  
     - Partition-based  
     - Hierarchical-based  
     - Density-based  
     - Distribution-based  

4. **Interpret and Adjust Results**  
   - Quality of clustering is iterative and exploratory.  
   - No labeled ground truth available.  
   - Verify results at cluster and example level.  
   - Iteratively experiment with data preparation, similarity measures, and algorithms.

## Important Terms
- **Unsupervised Learning**: Machine learning without labeled outputs.  
- **Clustering**: Grouping data items based on similarities.  
- **Outliers**: Items not belonging to any cluster.  
- **Market Segmentation**: Grouping customers by purchasing behavior.  
- **Outlier Analysis**: Identifying unusual patterns like fraud detection.  
- **Recommendation Systems**: Personalized suggestions based on clustering.  
- **Similarity**: Measure (0–1) of closeness between data points.  
- **Similarity Metrics**: Euclidean, Manhattan, Cosine, Jaccard.  

## Summary
- Unsupervised learning finds patterns in unlabeled data.  
- Clustering groups data based on similarities and identifies outliers.  
- Key use cases: market segmentation, fraud detection, recommendation systems.  
- Similarity measures are crucial in deciding clusters.  
- Workflow: data preparation → similarity matrix → clustering algorithm → interpret results.  
- Clustering is iterative, exploratory, and lacks labeled ground truth.  
