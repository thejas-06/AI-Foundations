# Customizing LLMs with Your Own Data - Learning Notes

## Overview
This lesson explains how you can customize **LLMs (Large Language Models)** to work with your own data. The framework is structured around two axes: **context optimization** and **LLM optimization**. It covers **prompt engineering**, **retrieval augmented generation (RAG)**, and **fine-tuning**, showing how these methods can be used individually or in combination. The lesson also provides examples of RAG implementations, explains how fine-tuning works, and gives guidance on when to use each method.

---

## Key Concepts
- **Context Optimization (Horizontal Axis)**: Providing more specific and detailed information for the LLM to draw from (e.g., user-specific data such as orders on a website).
- **LLM Optimization (Vertical Axis)**: Adapting the LLM to accomplish specific tasks or work within a given domain (e.g., fine-tuning on legal data).
- **Prompt Engineering**: The fastest and simplest starting point. Involves learning, testing, and iterating quickly.
- **Retrieval Augmented Generation (RAG)**: Allows LLMs to query enterprise knowledge bases (vector databases, wikis, etc.) for grounded responses.
- **Fine-Tuning**: Customizing a pre-trained foundational model with domain-specific data for better performance and efficiency.
- **Inference**: The process where a fine-tuned model generates outputs based on both pre-training and fine-tuning knowledge.
- **Grounded Response**: Text generated by the LLM that is supported by a document or database source.

---

## Detailed Notes

### Framework for Customizing LLMs
- **Horizontal Axis – Context Optimization**: Provide detailed, user-specific, or enterprise-specific information.  
- **Vertical Axis – LLM Optimization**: Adapt models for domain-specific tasks.  

### Prompt Engineering
- First and most obvious starting point.  
- Fastest and quickest method.  
- Allows rapid testing and iteration.  
- Often sufficient when the LLM already understands necessary topics.  

### Retrieval Augmented Generation (RAG)
- **Process**:  
  1. The LLM queries enterprise knowledge bases (e.g., vector databases, wikis).  
  2. Retrieves relevant information.  
  3. Uses it to generate a grounded response.  
- **Grounded Response**: The generated text is grounded in a document if the document supports the text.  
- **Example**:  
  - User wants to return a dress.  
  - Chatbot checks enterprise database for return policy (30–90 days, not on sale).  
  - User uploads a receipt.  
  - Vision service extracts sale details.  
  - Chatbot confirms eligibility for return.  
- **Advantages**:  
  - Does not require fine-tuning.  
  - Gives LLM access to private knowledge.  
  - Improves accuracy and usefulness.  
- **Two Major Components**:  
  - **Retrieval**: Searching over a corpus of relevant information.  
  - **Augmented Generation**: Using retrieved information to form responses.  

### Fine-Tuning and Inference
- **Fine-Tuning**:  
  - Take a pre-trained foundational model.  
  - Provide custom domain-specific data.  
  - Train the model further.  
  - Result: A fine-tuned model that adapts to a specific style, tone, and domain.  
- **Inference**:  
  - New text input → Model generates output.  
  - Uses both pre-training and fine-tuning knowledge.  
- **When to Use Fine-Tuning**:  
  - Pre-trained model does not perform tasks well.  
  - Teach the model new skills, tasks, or unique style.  
- **Advanced Approach (OCI - T-Few Fine-Tuning)**:  
  - Inserts new layers.  
  - Updates only a fraction of the model’s weights.  
  - Significantly reduces training time and cost.  
- **Benefits of Fine-Tuning**:  
  1. **Improved Model Performance**: Better contextually relevant responses.  
  2. **Improved Model Efficiency**: Fewer tokens, condenses expertise into a smaller model.  

### When to Use Each Method
- **Prompt Engineering**:  
  - No training cost.  
  - Use when the LLM already understands the required topics.  
- **RAG**:  
  - Use when data changes rapidly.  
  - Useful for mitigating hallucinations by grounding answers.  
  - **Advantages**: Grounded results, latest data access.  
  - **Disadvantages**: Requires a compatible and high-quality data source, more complex to set up.  
- **Fine-Tuning**:  
  - Use when the LLM does not perform well on a task.  
  - **Advantages**: Improves performance and efficiency.  
  - **Disadvantages**: Requires labeled datasets, time, and more resources.  

### Iterative Framework for Combining Methods
1. Start with prompt engineering and evaluation framework.  
2. Add few-shot examples to improve performance.  
3. Connect the model to enterprise knowledge base → RAG system.  
4. If results are still unsatisfactory, fine-tune the RAG-optimized model.  
5. If retrieval quality is low, optimize the retrieval system.  
6. Continue iterating, potentially using **all three methods together**.  

---

## Important Terms
- **Context Optimization**: Providing detailed, user-specific or enterprise-specific information.  
- **LLM Optimization**: Adapting LLMs for domain-specific tasks.  
- **Prompt Engineering**: Quick method for refining prompts to improve model responses.  
- **Retrieval Augmented Generation (RAG)**: Method that retrieves external data and uses it to generate grounded responses.  
- **Grounded Response**: Output supported by documents or data sources.  
- **Fine-Tuning**: Customizing a model with domain-specific data.  
- **Inference**: Model generating output based on training and fine-tuning.  
- **T-Few Fine-Tuning**: Advanced fine-tuning approach updating only part of a model’s weights.  

---

## Summary
- Customizing LLMs can be done along two axes: **context optimization** and **LLM optimization**.  
- **Prompt Engineering**: Fast, cost-free, good starting point.  
- **RAG**: Adds private knowledge, improves grounding, useful when data changes rapidly.  
- **Fine-Tuning**: Needed when LLMs underperform on tasks, improves both performance and efficiency.  
- Each method has advantages and disadvantages.  
- A practical workflow often uses **all three approaches iteratively**—starting with prompt engineering, adding RAG, and then applying fine-tuning if needed.  
